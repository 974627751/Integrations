{
  "id": "scrapewebsite_email",
  "title": "Scrape Website Email API",
  "description": "ScrapeWebsiteEmail is a service that exposes an api to fetch e-mails from a website.",
  "security": {},
  "actionCount": 3,
  "actions": [
    {
      "id": "v1.ping.json.get",
      "title": "v1.ping.json.get",
      "description": "Returns ‘pong’ if the site is up",
      "inputSchema": {},
      "outputSchema": {}
    },
    {
      "id": "v1.scrape_emails.json.get",
      "title": "v1.scrape_emails.json.get",
      "description": "Returns a list of emails scraped by priority (ie. e-mails appear on top level pages are first). Please note that subsequent calls to the same url will be fetched from the **cache** (14 day flush).  \n\nWill also parse patterns such as hello[at]site.com, hello[at]site[dot]com, hello(at)site.com, hello(at)site(dot)com, hello @ site.com, hello @ site . com.  \n\nPlease do note we cannot parse sites that require a login (for now), so for some Facebook pages it is not possible at the moment to fetch the e-mail.  \n\nFinally, please note that the api will fetch links for up to 2 minutes. After that time it will start analysing the pages which have been scraped. **Therefore** please ensure that your client has a timeout of at least **150 seconds** (2 mins to fetch and the rest to parse).  \n\n**Please note** that due to the fact that the api goes out to fetch the pages, the server allows only 1 concurrent request/ip. Requests which are made while the 1 request is still processing will result in a 429 code.  \n\n**Please note** that as of May 25, 2014, the main mechanism of tracking usage will be done via Mashape. You can get the free calls by signing up with the FREE plan.  \n\nPlease visit [https://www.mashape.com/tommytcchan/scrape-website-email](https://www.mashape.com/tommytcchan/scrape-website-email).  \n\n**There is now a limit of 5 requests per day using this sample interface.**",
      "inputSchema": {
        "type": "object",
        "properties": {
          "website": {
            "type": "string",
            "description": "<p>The website (ie. www.soundflair.com)</p>\n"
          },
          "must_include": {
            "type": "string",
            "description": "<table>\n  <tbody>\n    <tr>\n      <td>Optional. The word(s) that the webpage must include (otherwise it will skip scraping that page). Good if you want to scrape only contact pages. Takes regex (ie. about</td>\n      <td>contact).</td>\n    </tr>\n  </tbody>\n</table>\n"
          }
        },
        "additionalProperties": false,
        "required": [
          "website"
        ]
      },
      "outputSchema": {}
    },
    {
      "id": "v1.scrape_store_links.json.get",
      "title": "v1.scrape_store_links.json.get",
      "description": "Attempts to grab the google store url or the ios store url for a site, after searching through the site.",
      "inputSchema": {
        "type": "object",
        "properties": {
          "website": {
            "type": "string",
            "description": "<p>The website (ie. www.soundflair.com)</p>\n"
          }
        },
        "additionalProperties": false,
        "required": [
          "website"
        ]
      },
      "outputSchema": {}
    }
  ],
  "tags": [
    "email",
    "tools"
  ]
}